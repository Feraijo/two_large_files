# Есть 2 текстовых файла.
# Размер каждого файла несколько сотен Gb.
# В каждом файле содержатся записи вида:
# <ключ> - <значение>
# Ключ и значение - строки длиной около 100 символов.
# Ключи в первом файле уникальные и могут встречаться один 
#   или несколько раз или вообще не встречатся во втором файле.
# Необходимо написать программу сливающую эти два файла в 
#   третий по совпадению ключей следующим образом:
# <ключ_из_первого_файла> - <значение_из_первого_файла>, 
# <значение_из_второго_файла_1>, ... <значение_из_второго_файла_N>

import multiprocessing as mp

DELIMETER = b' - '

def proc(line):
    key, value = line.split(DELIMETER)    
    values = [value.strip()]
    with open('thicc_file2', 'br') as file2:
        for line in file2:
            if line.startswith(key):  
                values.append(line.split(DELIMETER)[1].strip())
    return key + DELIMETER + b', '.join(values) + b'\n'
    
if __name__ == '__main__': 
    with mp.Pool(mp.cpu_count()-1) as p:
        with open('thicc_file1', 'br') as file1:  
            with open('thicc_file_result', 'bw+') as result_file:          
                for line in p.map(proc, file1):                    
                    result_file.write(line)

# Код написан для худшего случая, когда второй файл составлен совершенно случайно. 
# Сложность такого алгоритма - O(m * n /), 
# (кол-во строк 1го файла)*(кол-во строк 2го файла)/кол-во ядер, участвующих в процессе
# т.е. требуется полный обход 2го файла на каждую строку из первого. 

# Добавляет возможных вариантов условие примерного соответствия оперативной 
# памяти и размера второго файла - можно попробовать defaultdict 
# или сортировку через терминал unix - sort.

# Ну и совсем отходя от темы - можно было бы импортировать файл в postgresql, 
# составить индексы и сделать задачу по-человечески
